---
title: "Reverse Engineering Project"
author: "Taylor Joel Shaun & Menna"
date: "7/7/23"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

In this notebook, we are reverse engineering the story, [Nearly 250 women have been shot by police since 2015](https://www.washingtonpost.com/graphics/2020/investigations/police-shootings-women/)

## Load libraries

Loading required libraries for this analysis.

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(lubridate)
library(janitor)
library(dplyr)
```

## Load and Cleaning Data

In this section, describe the source of the data, write a basic data dictionary for data you are working with, and discuss any caveats or issues you discovered working with this data. 

Our data comes from a database the Washington Post compiled with police shootings of citizens. It's unclear where exactly the Post gets its data from - presumably, skimming press releases from police departments. The biggest obstacle to us was the development of a new database version, V2. We were unable to verify some of the Post's numbers until we switched from V2 data (much more specific) to V1 data - and conversely were unable to verify some data with the V1 databse until we switched to V2 data.

```{r echo=FALSE, message=FALSE}
# This code sets the working directory to my local one (Taylor) - it will mess up your code, so erase this section and make sure yours is set to the correct working directory
setwd("~/data_journalism/data_journalism_fall_2023/major_assignments/reverse_engineering/Reverse-Engineering-Project/data")

# Load required data, should be loaded from folder "data" i.e. read_csv("data/name_of_data.csv")
fatal_police_shootings <- read_csv("data/fatal-police-shootings-data.csv")

# Clean required data and prepare for analysis if needed. 
clean_fatal_police_shootings <- fatal_police_shootings |> 
  clean_names()

# Filter for women.
women_fatal_police_shootings <- clean_fatal_police_shootings |>  
  filter(gender == "female") 

# Make the data column usable for analysis.
clean_fatal_police_shootings <- clean_fatal_police_shootings |> mutate(date=mdy(date))
women_fatal_police_shootings <- women_fatal_police_shootings |> mutate(date=mdy(date))

# Adjust the data frame so it reflects the database as it was when the Post published its story.
clean_fatal_police_shootings_2020 <- clean_fatal_police_shootings |>  
  filter(date<"2020-09-04")
```

## Sentences to Engineer
In this notebook, we are reverse engineering five sentences from the story.

### Sentence 1

* **Sentence text**: "Since The Washington Post began tracking fatal shootings by police in 2015, officers have fatally shot 247 women out of the more than 5,600 people killed overall."
* **Analysis summary**: We were able to get pretty close to the numbers quoted in the article. We came up with 248, one more than the Post included in their article. We weren't sure where the extra person was coming from - maybe police shot someone the same day as the Post published its article?

```{r}
# Reverse engineering sentence 1 to filter shootings after publication out.
women_fatal_police_shootings_2020 <- women_fatal_police_shootings |>
  filter(date<"2020-09-04") |> 
  summarize(count = n())

# Results
```

We're getting 1 more person than the Post did. Let's look at its original dataset to see if that makes a difference.

```{r}
setwd("~/data_journalism/data_journalism_fall_2023/major_assignments/reverse_engineering/Reverse-Engineering-Project/data")

data_to_sept_2020_shootings <- read_csv("data/2020_sept_3_fatal-police_shootings_data.csv")

# Clean required data and prepare for analysis. 
data_to_sept_2020_shootings <- data_to_sept_2020_shootings |> 
  clean_names()

women_fatal_police_shootings_sept_2020 <- data_to_sept_2020_shootings |>  
  filter(gender == "F") 

women_fatal_police_shootings_sept_2020 <- women_fatal_police_shootings_sept_2020 |>
  filter(date<"2020-09-04") |> 
  summarize(count = n())

```

It worked! We were able to verify the number the Post used in the article.

### Sentence 2

* **Sentence text**: Twenty of the 247 women were killed in that kind of situation, analysis shows. In 12 of those 20 shootings, police said the women killed were caught in crossfire or shot accidentally.
* **Analysis summary**: After a lot of struggling, we were able to figure out where the Post got its numbers from. The terms the Post used were quite vague (e.g. giving data about all women - 247 - while quoting Crenshaw about Black women). Not to be daunted, we tried every possibility we could think of to try to get matching numbers, including using the old dataset. Below is our data analysis.

The Post talks about Black women in the sentence but mentions 247 women. That number, we found, is the number  all women (of all races shot) and killed by police. Given that, we assumed the journalists meant women of all races.

```{r}
# Use V1 data to examine the threat_level variable in order to verify the Post's number for women that weren't suspects killed.

women_fatal_police_shootings_sept_2020 |> group_by(threat_level) |>
  summarise(count = n())

# Results
```

```{r}
# So none of these get close to the numbers we're looking for (20 or 12), nor do they mention anything about people not at fault. Let's try the v2 dataset:

women_fatal_police_shootings_2020 |> group_by(threat_type) |>
  summarise(count = n())
```

# Accident and flee add to 20. Those are probably our 20 magical women. We aren't entirely sure if this is what they did, but we don't know what else they could have done to get that number so that's what we're going to go with.

### Sentence 3

* **Sentence text**: At least 89 of the women [fatally shot by police] were at their homes or residences where they sometimes stayed.
* **Analysis summary**: We don't think this was determined through the dataset we have. There's no indicator of this info anywhere in either dataset. Presumably, the Post crawled through police reports that probably indicated whether the shooting was at the woman's house and from there got those statistics. We don't have access to those police reports, though, so we can only speculate; none of the Github data bares this out.

```{r}
# Put code to reverse engineer sentence here

# Display results of code below this codeblock

```

### Sentence 4

* **Sentence text**: About 31 percent, or 77, of the 247 women fatally shot by police since 2015 had mental health issues, compared to 22 percent of the 5,362 men killed.
* **Analysis summary**: We were able to confirm the findings using the original dataset Joel and Shaun found that reflects what info they had when the article came out. That means we should probably use this dataset going forward, though it's strange that we got to the 20 answer thanks to the V2 dataset. Maybe the Post was already testing V2 at the time?

```{r}
# Put code to reverse engineer sentence here
data_to_sept_2020_shootings |> 
  group_by(gender, signs_of_mental_illness) |>
  summarise(count = n())
# Display results of code below this codeblock
```

This is looking more accurate. 77 out of 247 women and 22% of men had signs of mental illness.
### Sentence 5

* **Sentence text**: Since 2015, police have killed 26 unarmed women, including Taylor.
* **Analysis summary**: This was the easiest finding to confirm. A simple column analysis reveals that 26 unarmed women were killed up until the date of publication.

```{r}
# Put code to reverse engineer sentence here
## using v1 data
women_fatal_police_shootings_sept_2020 |> 
  group_by(armed) |> 
  summarize(count=n())

# Display results of code below this codeblock

```

-30-